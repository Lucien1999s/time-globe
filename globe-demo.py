import time
import random
import html
import urllib.parse
import requests
from bs4 import BeautifulSoup

DUCK_LITE_SEARCH = "https://lite.duckduckgo.com/lite/"

def _human_user_agent():
    return (
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/119.0.0.0 Safari/537.36"
    )

def _fetch(url, params=None, timeout=12, max_retries=2, backoff=0.8):
    headers = {"User-Agent": _human_user_agent()}
    for attempt in range(max_retries + 1):
        try:
            r = requests.get(url, params=params, headers=headers, timeout=timeout)
            # ä»¥ 200 è¦–ç‚ºæˆåŠŸï¼›å…¶ä»–ç‹€æ…‹ç¢¼ä¹Ÿå˜—è©¦å›å‚³ä»¥åˆ©é™¤éŒ¯
            if r.status_code == 200 and r.text:
                return r.text
            # è¼•é‡é€€é¿
            time.sleep(backoff * (attempt + 1))
        except requests.RequestException:
            time.sleep(backoff * (attempt + 1))
    return ""

def _parse_duck_lite(html_text, max_results=5):
    """
    è§£æ DuckDuckGo Lite çµæœé ã€‚
    çµæ§‹ï¼š<table> ä¸­çš„å¤šå€‹ <tr>ï¼›æ¯å€‹çµæœé€šå¸¸åœ¨ <a> å¾Œè·Ÿæè¿°æ–‡å­—ã€‚
    """
    soup = BeautifulSoup(html_text, "html.parser")
    results = []
    # Lite ç‰ˆçµæœå¸¸è¦‹åœ¨å¤šå€‹ <tr> å…§ï¼Œé€£çµç‚º <a>ï¼›ç›¸é„°æ–‡å­—ç‚ºæ‘˜è¦
    for a in soup.select("a"):
        href = a.get("href", "")
        text = a.get_text(" ", strip=True)
        if not href or not text:
            continue
        # éæ¿¾å°èˆª/å…§éƒ¨é€£çµ
        if href.startswith("/") or "duckduckgo.com" in href:
            continue
        # æ‰¾å¯èƒ½çš„æ‘˜è¦ï¼ˆa æ‰€åœ¨è¡Œçš„å¾ŒçºŒæ–‡å­—ï¼‰
        summary = ""
        # å˜—è©¦å¾çˆ¶å±¤ <td>/<tr> æ“·å–ç›¸é„°æ–‡å­—
        parent = a.find_parent(["td", "tr"])
        if parent:
            # å–å¾—çˆ¶å±¤æ–‡å­—ï¼Œç§»é™¤æ¨™é¡Œæ–‡å­—æœ¬èº«
            parent_text = parent.get_text(" ", strip=True)
            # é¿å…é‡è¤‡æ¨™é¡Œï¼Œä¸¦é©åº¦æˆªæ–·
            summary = parent_text.replace(text, "").strip()
            # æ¸…æ‰å¤šé¤˜å†’è™Ÿèˆ‡ç©ºç™½
            summary = summary.lstrip(":-â€”| ").strip()
        # ä¹¾æ·¨åŒ– URL
        clean_url = html.unescape(href)
        results.append((text, clean_url, summary))
        if len(results) >= max_results:
            break
    return results

def web_search(query: str, max_results: int = 5, polite_delay_sec: float = None) -> str:
    """
    å…é‡‘é‘° Web æœå°‹ï¼šè¼¸å…¥ strã€è¼¸å‡ºæ•´æ®µ strã€‚
    ä¸»è¦ä½¿ç”¨ DuckDuckGo Lite çµæœé ï¼Œè§£ææ¨™é¡Œã€URLã€æ‘˜è¦ã€‚
    """
    if polite_delay_sec is None:
        polite_delay_sec = round(random.uniform(0.4, 0.9), 2)  # ç¦®è²Œæ€§å»¶é²

    q = query.strip()
    if not q:
        return "ï¼ˆéŒ¯èª¤ï¼‰è«‹æä¾›éç©ºç™½çš„æŸ¥è©¢å­—ä¸²ã€‚"

    # å–å¾—çµæœé  HTML
    payload = {"q": q}
    html_text = _fetch(DUCK_LITE_SEARCH, params=payload)
    if not html_text:
        return "ï¼ˆæœå°‹å¤±æ•—ï¼‰ç›®å‰ç„¡æ³•å–å¾—æœå°‹çµæœï¼Œå¯èƒ½æ˜¯ç¶²è·¯æˆ–å°æ–¹æš«æ™‚æ‹’çµ•é€£ç·šã€‚ç¨å¾Œå†è©¦ã€‚"

    rows = _parse_duck_lite(html_text, max_results=max_results)
    if not rows:
        return "ï¼ˆæ²’æœ‰çµæœï¼‰å¯èƒ½æ˜¯æœå°‹èªæ³•éæ–¼ç‰¹æ®Šï¼Œè«‹å˜—è©¦æ›´ç°¡æ½”çš„é—œéµå­—ã€‚"

    # çµ„è£è¼¸å‡ºå­—ä¸²
    lines = [f"ğŸ” æŸ¥è©¢ï¼š{q}", "-" * 48]
    for i, (title, url, summary) in enumerate(rows, 1):
        # ç°¡å–®æˆªæ–·æ‘˜è¦ï¼Œé¿å…éé•·
        if len(summary) > 220:
            summary = summary[:217] + "..."
        # é˜²æ­¢ URL éé•·é€ æˆæ›è¡Œæ··äº‚
        if len(url) > 200:
            short_url = url[:197] + "..."
        else:
            short_url = url
        lines.append(f"{i}. {title}\n   {short_url}")
        if summary:
            lines.append(f"   â”” æ‘˜è¦ï¼š{summary}")
        lines.append("")  # ç©ºè¡Œåˆ†éš”
        # ç¦®è²Œæ€§å»¶é²ï¼Œé¿å…å¤ªé »ç¹è«‹æ±‚
        time.sleep(polite_delay_sec)

    return "\n".join(lines).strip()

# --- ç¯„ä¾‹åŸ·è¡Œ ---
if __name__ == "__main__":
    example_query = "TensorRT-LLM FP8 tutorial"
    output = web_search(example_query, max_results=5)
    print(output)
